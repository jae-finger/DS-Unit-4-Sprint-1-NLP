{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 1*\n",
    "\n",
    "---\n",
    "<h1 id=\"moduleTitle\"> Natural Language Processing Introduction (Prepare)</h1>\n",
    "\n",
    "\"Natural\" meaning - not computer languages but spoken/written human languages. The hard thing about NLP is that human languages are far less structured or consistent than computer languages. This is perhaps the largest source of difficulty when trying to get computers to \"understand\" human languages. How do you get a machine to understand sarcasm, and irony, and synonyms, connotation, denotation, nuance, and tone of voice --all without it having lived a lifetime of experience for context? If you think about it, our human brains have been exposed to quite a lot of training data to help us interpret languages, and even then we misunderstand each other pretty frequently. \n",
    "    \n",
    "\n",
    "<h2 id='moduleObjectives'>Learning Objectives</h2>\n",
    "\n",
    "By the end of end of this module, a student should be able to:\n",
    "* <a href=\"#p1\">Objective 1</a>: Tokenize text\n",
    "* <a href=\"#p1\">Objective 2</a>: Remove stop words from text\n",
    "* <a href=\"#p3\">Objective 3</a>: Perform stemming and lemmatization on tokens\n",
    "\n",
    "## Conda Environments\n",
    "\n",
    "You will be completing each module this sprint on your machine. We will be using conda environments to manage the packages and their dependencies for this sprint's content. In a classroom setting, instructors typically abstract away environment for you. However, environment management is an important professional data science skill. We showed you how to manage environments using pipvirtual env during Unit 3, but in this sprint, we will introduce an environment management tool common in the data science community: \n",
    "\n",
    "> __conda__: Package, dependency and environment management for any languageâ€”Python, R, Ruby, Lua, Scala, Java, JavaScript, C/ C++, FORTRAN, and more.\n",
    "\n",
    "The easiest way to install conda on your machine is via the [Anaconda Distribution](https://www.anaconda.com/distribution/) of Python & R. Once you have conda installed, read [\"A Guide to Conda Environments\"](https://towardsdatascience.com/a-guide-to-conda-environments-bc6180fc533). This article will provide an introduce into some of the conda basics. If you need some additional help getting started, the official [\"Setting started with conda\"](https://conda.io/projects/conda/en/latest/user-guide/getting-started.html) guide will point you in the right direction. \n",
    "\n",
    ":snake: \n",
    "\n",
    "To get the sprint environment setup: \n",
    "\n",
    "1. Open your command line tool (Terminal for MacOS, Anaconda Prompt for Windows)\n",
    "2. Navigate to the folder with this sprint's content. There should be a `requirements.txt`\n",
    "3. Run `conda create -n U4-S1-NLP python==3.7` => You can also rename the environment if you would like. Once the command completes, your conda environment should be ready.\n",
    "4. Now, we are going to add in the require python packages for this sprint. You will need to 'activate' the conda environment: `source activate U4-S1-NLP` on Terminal or `conda activate U4-S1-NLP` on Anaconda Prompt. Once your environment is activate, run `pip install -r requirements.txt` which will install the required packages into your environment.\n",
    "5. We are going to also add an Ipython Kernel reference to your conda environment, so we can use it from JupyterLab. \n",
    "6. Next run `python -m ipykernel install --user --name U4-S1-NLP --display-name \"U4-S1-NLP (Python3)\"` => This will add a json object to an ipython file, so JupterLab will know that it can use this isolated instance of Python. :) \n",
    "7. Last step, we need to install the models for Spacy. Run these commands `python -m spacy download en_core_web_md` and `python -m spacy download en_core_web_lg`\n",
    "8. Deactivate your conda environment and launch JupyterLab. You should know see \"U4-S1-NLP (Python3)\" in the list of available kernels on launch screen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Tokenze Text (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Overview\n",
    "\n",
    "> **token**: an instance of a sequence of characters in some particular document that are grouped together as a useful semantic unit for processing\n",
    "\n",
    "> [_*Introduction to Information Retrival*_](https://nlp.stanford.edu/IR-book/)\n",
    "\n",
    "\n",
    "### The attributes of good tokens\n",
    "\n",
    "* Should be stored in an iterable data structure\n",
    "  - Allows analysis of the \"semantic unit\"\n",
    "* Should be all the same case\n",
    "  - Reduces the complexity of our data\n",
    "* Should be free of non-alphanumeric characters (ie punctuation, whitespace)\n",
    "  - Removes information that is probably not relevant to the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libariries\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Plotting\n",
    "import squarify\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# NLP Libraries\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pretend we are trying analyze the random sequence here. Question: what is the most common character in this sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seq = \"AABAAFBBBBCGCDDEEEFCFFDFFAFFZFGGGGHEAFJAAZBBFCZ\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful unit of analysis for us is going to be a letter or character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'A', 'B', 'A', 'A', 'F', 'B', 'B', 'B', 'B', 'C', 'G', 'C', 'D', 'D', 'E', 'E', 'E', 'F', 'C', 'F', 'F', 'D', 'F', 'F', 'A', 'F', 'F', 'Z', 'F', 'G', 'G', 'G', 'G', 'H', 'E', 'A', 'F', 'J', 'A', 'A', 'Z', 'B', 'B', 'F', 'C', 'Z']\n"
     ]
    }
   ],
   "source": [
    "tokens = list(random_seq)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our tokens are already \"good\": in an iterable datastructure, all the same case, and free of noise characters (punctuation, whitespace), so we can jump straight into analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(tokens);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common character in our sequence is  \"F\". We can't just glance at the the sequence to know which character is the most common. We (humans) struggle to subitize complex data (like random text sequences).\n",
    "\n",
    "> __Subitize__ is the ability to tell the number of objects in a set, quickly, without counting.  \n",
    "\n",
    "We need to chunk the data into countable pieces \"tokens\" for us to analyze them. This inability subitize text data is the motivation for our discussion today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Tokenizing with Pure Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"Friends, Romans, countrymen, lend me your ears;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Iterable Tokens\n",
    "\n",
    "A string object in Python is already iterable. However, the item you iterate over is a character not a token:\n",
    "\n",
    "```\n",
    "from time import sleep\n",
    "for num, character in enumerate(sample):\n",
    "    sleep(.5)\n",
    "    print(f\"Char {num} - {character}\", end=\"\\r\")\n",
    "```\n",
    "\n",
    "If we instead care about the words in our sample (our semantic unit), we can use the string method `.split()` to separate the whitespace and create iterable units. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mod__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'capitalize',\n",
       " 'casefold',\n",
       " 'center',\n",
       " 'count',\n",
       " 'encode',\n",
       " 'endswith',\n",
       " 'expandtabs',\n",
       " 'find',\n",
       " 'format',\n",
       " 'format_map',\n",
       " 'index',\n",
       " 'isalnum',\n",
       " 'isalpha',\n",
       " 'isascii',\n",
       " 'isdecimal',\n",
       " 'isdigit',\n",
       " 'isidentifier',\n",
       " 'islower',\n",
       " 'isnumeric',\n",
       " 'isprintable',\n",
       " 'isspace',\n",
       " 'istitle',\n",
       " 'isupper',\n",
       " 'join',\n",
       " 'ljust',\n",
       " 'lower',\n",
       " 'lstrip',\n",
       " 'maketrans',\n",
       " 'partition',\n",
       " 'replace',\n",
       " 'rfind',\n",
       " 'rindex',\n",
       " 'rjust',\n",
       " 'rpartition',\n",
       " 'rsplit',\n",
       " 'rstrip',\n",
       " 'split',\n",
       " 'splitlines',\n",
       " 'startswith',\n",
       " 'strip',\n",
       " 'swapcase',\n",
       " 'title',\n",
       " 'translate',\n",
       " 'upper',\n",
       " 'zfill']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sample) # shows us everything we can do to this text sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Friends,', 'Romans,', 'countrymen,', 'lend', 'me', 'your', 'ears;']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Case Normalization\n",
    "A common data cleaning data cleaning task with token is to standardize or normalize the case. Normalizing case reduces the chance that you have duplicate records for things which have practically the same semantic meaning. You can use either the `.lower()` or `.upper()` string methods to normalize case.\n",
    "\n",
    "Consider the following example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28332, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>dateUpdated</th>\n",
       "      <th>name</th>\n",
       "      <th>asins</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>primaryCategories</th>\n",
       "      <th>imageURLs</th>\n",
       "      <th>keys</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.didPurchase</th>\n",
       "      <th>reviews.doRecommend</th>\n",
       "      <th>reviews.id</th>\n",
       "      <th>reviews.numHelpful</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.username</th>\n",
       "      <th>sourceURLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
       "      <td>2015-10-30T08:59:32Z</td>\n",
       "      <td>2019-04-25T09:08:16Z</td>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
       "      <td>I order 3 of them and one of the item is bad q...</td>\n",
       "      <td>... 3 of them and one of the item is bad quali...</td>\n",
       "      <td>Byger yang</td>\n",
       "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
       "      <td>2015-10-30T08:59:32Z</td>\n",
       "      <td>2019-04-25T09:08:16Z</td>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
       "      <td>Bulk is always the less expensive way to go fo...</td>\n",
       "      <td>... always the less expensive way to go for pr...</td>\n",
       "      <td>ByMG</td>\n",
       "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
       "      <td>2015-10-30T08:59:32Z</td>\n",
       "      <td>2019-04-25T09:08:16Z</td>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
       "      <td>Well they are not Duracell but for the price i...</td>\n",
       "      <td>... are not Duracell but for the price i am ha...</td>\n",
       "      <td>BySharon Lambert</td>\n",
       "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
       "      <td>2015-10-30T08:59:32Z</td>\n",
       "      <td>2019-04-25T09:08:16Z</td>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
       "      <td>Seem to work as well as name brand batteries a...</td>\n",
       "      <td>... as well as name brand batteries at a much ...</td>\n",
       "      <td>Bymark sexson</td>\n",
       "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
       "      <td>2015-10-30T08:59:32Z</td>\n",
       "      <td>2019-04-25T09:08:16Z</td>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
       "      <td>These batteries are very long lasting the pric...</td>\n",
       "      <td>... batteries are very long lasting the price ...</td>\n",
       "      <td>Bylinda</td>\n",
       "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id             dateAdded           dateUpdated  \\\n",
       "0  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
       "1  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
       "2  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
       "3  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
       "4  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
       "\n",
       "                                                name                  asins  \\\n",
       "0  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
       "1  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
       "2  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
       "3  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
       "4  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
       "\n",
       "          brand                                         categories  \\\n",
       "0  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
       "1  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
       "2  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
       "3  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
       "4  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
       "\n",
       "  primaryCategories                                          imageURLs  \\\n",
       "0   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
       "1   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
       "2   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
       "3   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
       "4   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
       "\n",
       "                                                keys  ... reviews.didPurchase  \\\n",
       "0  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
       "1  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
       "2  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
       "3  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
       "4  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
       "\n",
       "  reviews.doRecommend reviews.id reviews.numHelpful reviews.rating  \\\n",
       "0                 NaN        NaN                NaN              3   \n",
       "1                 NaN        NaN                NaN              4   \n",
       "2                 NaN        NaN                NaN              5   \n",
       "3                 NaN        NaN                NaN              5   \n",
       "4                 NaN        NaN                NaN              5   \n",
       "\n",
       "                                  reviews.sourceURLs  \\\n",
       "0  https://www.amazon.com/product-reviews/B00QWO9...   \n",
       "1  https://www.amazon.com/product-reviews/B00QWO9...   \n",
       "2  https://www.amazon.com/product-reviews/B00QWO9...   \n",
       "3  https://www.amazon.com/product-reviews/B00QWO9...   \n",
       "4  https://www.amazon.com/product-reviews/B00QWO9...   \n",
       "\n",
       "                                        reviews.text  \\\n",
       "0  I order 3 of them and one of the item is bad q...   \n",
       "1  Bulk is always the less expensive way to go fo...   \n",
       "2  Well they are not Duracell but for the price i...   \n",
       "3  Seem to work as well as name brand batteries a...   \n",
       "4  These batteries are very long lasting the pric...   \n",
       "\n",
       "                                       reviews.title  reviews.username  \\\n",
       "0  ... 3 of them and one of the item is bad quali...        Byger yang   \n",
       "1  ... always the less expensive way to go for pr...              ByMG   \n",
       "2  ... are not Duracell but for the price i am ha...  BySharon Lambert   \n",
       "3  ... as well as name brand batteries at a much ...     Bymark sexson   \n",
       "4  ... batteries are very long lasting the price ...           Bylinda   \n",
       "\n",
       "                                          sourceURLs  \n",
       "0  https://www.barcodable.com/upc/841710106442,ht...  \n",
       "1  https://www.barcodable.com/upc/841710106442,ht...  \n",
       "2  https://www.barcodable.com/upc/841710106442,ht...  \n",
       "3  https://www.barcodable.com/upc/841710106442,ht...  \n",
       "4  https://www.barcodable.com/upc/841710106442,ht...  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Amazon          16153\n",
       "Amazonbasics    12169\n",
       "AmazonBasics       10\n",
       "Name: brand, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice anything odd here? \n",
    "df['brand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amazon          16153\n",
       "amazonbasics    12179\n",
       "Name: brand, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Much cleaner\n",
    "df['brand'] = df['brand'].apply(lambda x: x.lower())\n",
    "df['brand'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Keep Only Alphanumeric Characters\n",
    "Yes, we only want letters and numbers. Everything else is probably noise: punctuation, whitespace, and other notation. This one is little bit more complicated than our previous example. Here we will have to import the base package `re` (regular expressions). \n",
    "\n",
    "The only regex expression pattern you need for this is `'[^a-zA-Z 0-9]'` which keeps lower case letters, upper case letters, spaces, and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friends, Romans, countrymen, lend me your ears; 911\n"
     ]
    }
   ],
   "source": [
    "sample = sample+\" 911\"\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Friends Romans countrymen lend me your ears 911'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('[^a-zA-Z 0-9]', '', sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Minute Challenge \n",
    "- Complete the function `tokenize` below\n",
    "- Combine the methods which we discussed above to clean text before we analyze it\n",
    "- You can put the methods in any order you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Parses a string into a list of semantic units (words)\n",
    "\n",
    "    Args:\n",
    "        text (str): The string that the function will tokenize.\n",
    "\n",
    "    Returns:\n",
    "        list: tokens parsed out by the mechanics of your choice\n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = re.sub('[^a-zA-Z 0-9]', '', text)\n",
    "    tokens = tokens.lower().split()\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['friends', 'romans', 'countrymen', 'lend', 'me', 'your', 'ears', '911']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along\n",
    "\n",
    "Our inability to analyze text data becomes quickly amplified in a business context. Consider the following: \n",
    "\n",
    "A business which sells widgets also collects customer reviews of those widgets. When the business first started out, they had a human read the reviews to look for patterns. Now, the business sells thousands of widgets a month. The human readers can't keep up with the pace of reviews to synthesize an accurate analysis. They need some science to help them analyze their data.\n",
    "\n",
    "Now, let's pretend that business is Amazon, and the widgets are Amazon products such as the Alexa, Echo, or other AmazonBasics products. Let's analyze their reviews with some counts. This dataset is available on [Kaggle](https://www.kaggle.com/datafiniti/consumer-reviews-of-amazon-products/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good                0.002118\n",
       "great               0.001729\n",
       "Good                0.001482\n",
       "Great               0.001341\n",
       "ok                  0.001165\n",
       "Great price         0.001059\n",
       "great price         0.000988\n",
       "Excellent           0.000988\n",
       "Great value         0.000953\n",
       "good price          0.000812\n",
       "great value         0.000777\n",
       "Great price!        0.000635\n",
       "good value          0.000600\n",
       "good deal           0.000565\n",
       "Great value.        0.000565\n",
       "OK                  0.000529\n",
       "Good deal           0.000529\n",
       "Great product       0.000529\n",
       "As expected         0.000529\n",
       "Great deal          0.000529\n",
       "Good value          0.000494\n",
       "Good batteries      0.000494\n",
       "Great batteries.    0.000459\n",
       "great deal          0.000459\n",
       "Good price          0.000459\n",
       "Great value!        0.000459\n",
       "So far so good      0.000459\n",
       "Work great          0.000424\n",
       "Good buy            0.000424\n",
       "excellent           0.000388\n",
       "as expected         0.000388\n",
       "Great deal!         0.000388\n",
       "Great price.        0.000388\n",
       "good batteries      0.000388\n",
       "Great batteries     0.000388\n",
       "Great buy           0.000388\n",
       "Great!              0.000388\n",
       "Good value.         0.000388\n",
       "very good           0.000388\n",
       "As described        0.000388\n",
       "Work great.         0.000353\n",
       "Nice                0.000353\n",
       "good product        0.000353\n",
       "Perfect!            0.000353\n",
       "great batteries     0.000353\n",
       "Ok                  0.000353\n",
       "Thanks              0.000318\n",
       "Very good           0.000318\n",
       "Great buy!          0.000318\n",
       "Good price.         0.000318\n",
       "Name: reviews.text, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How can we count the raw text?\n",
    "df['reviews.text'].value_counts(normalize=True)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [i, order, 3, of, them, and, one, of, the, ite...\n",
       "1    [bulk, is, always, the, less, expensive, way, ...\n",
       "2    [well, they, are, not, duracell, but, for, the...\n",
       "3    [seem, to, work, as, well, as, name, brand, ba...\n",
       "4    [these, batteries, are, very, long, lasting, t...\n",
       "Name: base_tokens, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['base_tokens'] = df['reviews.text'].apply(tokenize)\n",
    "df['base_tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>base_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I order 3 of them and one of the item is bad q...</td>\n",
       "      <td>[i, order, 3, of, them, and, one, of, the, ite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bulk is always the less expensive way to go fo...</td>\n",
       "      <td>[bulk, is, always, the, less, expensive, way, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well they are not Duracell but for the price i...</td>\n",
       "      <td>[well, they, are, not, duracell, but, for, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seem to work as well as name brand batteries a...</td>\n",
       "      <td>[seem, to, work, as, well, as, name, brand, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>These batteries are very long lasting the pric...</td>\n",
       "      <td>[these, batteries, are, very, long, lasting, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bought a lot of batteries for Christmas and th...</td>\n",
       "      <td>[bought, a, lot, of, batteries, for, christmas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ive not had any problame with these batteries ...</td>\n",
       "      <td>[ive, not, had, any, problame, with, these, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Well if you are looking for cheap non-recharge...</td>\n",
       "      <td>[well, if, you, are, looking, for, cheap, nonr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>These do not hold the amount of high power jui...</td>\n",
       "      <td>[these, do, not, hold, the, amount, of, high, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AmazonBasics AA AAA batteries have done well b...</td>\n",
       "      <td>[amazonbasics, aa, aaa, batteries, have, done,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        reviews.text  \\\n",
       "0  I order 3 of them and one of the item is bad q...   \n",
       "1  Bulk is always the less expensive way to go fo...   \n",
       "2  Well they are not Duracell but for the price i...   \n",
       "3  Seem to work as well as name brand batteries a...   \n",
       "4  These batteries are very long lasting the pric...   \n",
       "5  Bought a lot of batteries for Christmas and th...   \n",
       "6  ive not had any problame with these batteries ...   \n",
       "7  Well if you are looking for cheap non-recharge...   \n",
       "8  These do not hold the amount of high power jui...   \n",
       "9  AmazonBasics AA AAA batteries have done well b...   \n",
       "\n",
       "                                         base_tokens  \n",
       "0  [i, order, 3, of, them, and, one, of, the, ite...  \n",
       "1  [bulk, is, always, the, less, expensive, way, ...  \n",
       "2  [well, they, are, not, duracell, but, for, the...  \n",
       "3  [seem, to, work, as, well, as, name, brand, ba...  \n",
       "4  [these, batteries, are, very, long, lasting, t...  \n",
       "5  [bought, a, lot, of, batteries, for, christmas...  \n",
       "6  [ive, not, had, any, problame, with, these, ba...  \n",
       "7  [well, if, you, are, looking, for, cheap, nonr...  \n",
       "8  [these, do, not, hold, the, amount, of, high, ...  \n",
       "9  [amazonbasics, aa, aaa, batteries, have, done,...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['reviews.text', 'base_tokens']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Electronics                    13995\n",
       "Health & Beauty                12071\n",
       "Toys & Games,Electronics        1676\n",
       "Office Supplies,Electronics      386\n",
       "Electronics,Media                185\n",
       "Office Supplies                    9\n",
       "Animals & Pet Supplies             6\n",
       "Electronics,Furniture              2\n",
       "Home & Garden                      2\n",
       "Name: primaryCategories, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['primaryCategories'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>dateUpdated</th>\n",
       "      <th>name</th>\n",
       "      <th>asins</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>primaryCategories</th>\n",
       "      <th>imageURLs</th>\n",
       "      <th>keys</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.doRecommend</th>\n",
       "      <th>reviews.id</th>\n",
       "      <th>reviews.numHelpful</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.username</th>\n",
       "      <th>sourceURLs</th>\n",
       "      <th>base_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8343</th>\n",
       "      <td>AVpe7nGV1cnluZ0-aG2o</td>\n",
       "      <td>2014-10-28T11:14:38Z</td>\n",
       "      <td>2019-04-25T09:05:28Z</td>\n",
       "      <td>AmazonBasics Nylon CD/DVD Binder (400 Capacity)</td>\n",
       "      <td>B00DIHVMEA,B00EZ1ZTV0</td>\n",
       "      <td>amazonbasics</td>\n",
       "      <td>Audio &amp; Video Accessories,TV, Video &amp; Home Aud...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41jQha7Z...</td>\n",
       "      <td>amazonbasicsnyloncddvdbinder400capacity/b00ez1...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.ebay.com/itm/Amazonbasics-Nylon-Cd...</td>\n",
       "      <td>Great case to keep everything in its place! My...</td>\n",
       "      <td>Excellent product</td>\n",
       "      <td>qs341_5</td>\n",
       "      <td>https://www.ebay.com/itm/AmazonBasics-Nylon-CD...</td>\n",
       "      <td>[great, case, to, keep, everything, in, its, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8344</th>\n",
       "      <td>AVpe7nGV1cnluZ0-aG2o</td>\n",
       "      <td>2014-10-28T11:14:38Z</td>\n",
       "      <td>2019-04-25T09:05:28Z</td>\n",
       "      <td>AmazonBasics Nylon CD/DVD Binder (400 Capacity)</td>\n",
       "      <td>B00DIHVMEA,B00EZ1ZTV0</td>\n",
       "      <td>amazonbasics</td>\n",
       "      <td>Audio &amp; Video Accessories,TV, Video &amp; Home Aud...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41jQha7Z...</td>\n",
       "      <td>amazonbasicsnyloncddvdbinder400capacity/b00ez1...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>http://www.amazon.co.uk/gp/product-reviews/B00...</td>\n",
       "      <td>After discarding and getting rid of broken cd ...</td>\n",
       "      <td>It was a much needed storage</td>\n",
       "      <td>Diablita</td>\n",
       "      <td>https://www.ebay.com/itm/AmazonBasics-Nylon-CD...</td>\n",
       "      <td>[after, discarding, and, getting, rid, of, bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8345</th>\n",
       "      <td>AVpe7nGV1cnluZ0-aG2o</td>\n",
       "      <td>2014-10-28T11:14:38Z</td>\n",
       "      <td>2019-04-25T09:05:28Z</td>\n",
       "      <td>AmazonBasics Nylon CD/DVD Binder (400 Capacity)</td>\n",
       "      <td>B00DIHVMEA,B00EZ1ZTV0</td>\n",
       "      <td>amazonbasics</td>\n",
       "      <td>Audio &amp; Video Accessories,TV, Video &amp; Home Aud...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41jQha7Z...</td>\n",
       "      <td>amazonbasicsnyloncddvdbinder400capacity/b00ez1...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.ebay.com/itm/Amazonbasics-Nylon-Cd...</td>\n",
       "      <td>A few dollars more, but I am boycotting amazon</td>\n",
       "      <td>it was worth it</td>\n",
       "      <td>coldbloodblazing</td>\n",
       "      <td>https://www.ebay.com/itm/AmazonBasics-Nylon-CD...</td>\n",
       "      <td>[a, few, dollars, more, but, i, am, boycotting...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id             dateAdded           dateUpdated  \\\n",
       "8343  AVpe7nGV1cnluZ0-aG2o  2014-10-28T11:14:38Z  2019-04-25T09:05:28Z   \n",
       "8344  AVpe7nGV1cnluZ0-aG2o  2014-10-28T11:14:38Z  2019-04-25T09:05:28Z   \n",
       "8345  AVpe7nGV1cnluZ0-aG2o  2014-10-28T11:14:38Z  2019-04-25T09:05:28Z   \n",
       "\n",
       "                                                 name                  asins  \\\n",
       "8343  AmazonBasics Nylon CD/DVD Binder (400 Capacity)  B00DIHVMEA,B00EZ1ZTV0   \n",
       "8344  AmazonBasics Nylon CD/DVD Binder (400 Capacity)  B00DIHVMEA,B00EZ1ZTV0   \n",
       "8345  AmazonBasics Nylon CD/DVD Binder (400 Capacity)  B00DIHVMEA,B00EZ1ZTV0   \n",
       "\n",
       "             brand                                         categories  \\\n",
       "8343  amazonbasics  Audio & Video Accessories,TV, Video & Home Aud...   \n",
       "8344  amazonbasics  Audio & Video Accessories,TV, Video & Home Aud...   \n",
       "8345  amazonbasics  Audio & Video Accessories,TV, Video & Home Aud...   \n",
       "\n",
       "     primaryCategories                                          imageURLs  \\\n",
       "8343       Electronics  http://ecx.images-amazon.com/images/I/41jQha7Z...   \n",
       "8344       Electronics  http://ecx.images-amazon.com/images/I/41jQha7Z...   \n",
       "8345       Electronics  http://ecx.images-amazon.com/images/I/41jQha7Z...   \n",
       "\n",
       "                                                   keys  ...  \\\n",
       "8343  amazonbasicsnyloncddvdbinder400capacity/b00ez1...  ...   \n",
       "8344  amazonbasicsnyloncddvdbinder400capacity/b00ez1...  ...   \n",
       "8345  amazonbasicsnyloncddvdbinder400capacity/b00ez1...  ...   \n",
       "\n",
       "     reviews.doRecommend reviews.id reviews.numHelpful reviews.rating  \\\n",
       "8343                 NaN        NaN                NaN              5   \n",
       "8344                 NaN        NaN                NaN              5   \n",
       "8345                 NaN        NaN                NaN              5   \n",
       "\n",
       "                                     reviews.sourceURLs  \\\n",
       "8343  https://www.ebay.com/itm/Amazonbasics-Nylon-Cd...   \n",
       "8344  http://www.amazon.co.uk/gp/product-reviews/B00...   \n",
       "8345  https://www.ebay.com/itm/Amazonbasics-Nylon-Cd...   \n",
       "\n",
       "                                           reviews.text  \\\n",
       "8343  Great case to keep everything in its place! My...   \n",
       "8344  After discarding and getting rid of broken cd ...   \n",
       "8345     A few dollars more, but I am boycotting amazon   \n",
       "\n",
       "                     reviews.title  reviews.username  \\\n",
       "8343             Excellent product           qs341_5   \n",
       "8344  It was a much needed storage          Diablita   \n",
       "8345               it was worth it  coldbloodblazing   \n",
       "\n",
       "                                             sourceURLs  \\\n",
       "8343  https://www.ebay.com/itm/AmazonBasics-Nylon-CD...   \n",
       "8344  https://www.ebay.com/itm/AmazonBasics-Nylon-CD...   \n",
       "8345  https://www.ebay.com/itm/AmazonBasics-Nylon-CD...   \n",
       "\n",
       "                                            base_tokens  \n",
       "8343  [great, case, to, keep, everything, in, its, p...  \n",
       "8344  [after, discarding, and, getting, rid, of, bro...  \n",
       "8345  [a, few, dollars, more, but, i, am, boycotting...  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['primaryCategories'] == 'Electronics'].copy()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 17723),\n",
       " ('and', 14005),\n",
       " ('it', 13113),\n",
       " ('to', 12750),\n",
       " ('for', 12224),\n",
       " ('i', 12037),\n",
       " ('a', 10494),\n",
       " ('is', 8508),\n",
       " ('this', 8109),\n",
       " ('my', 7914)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The object `Counter` takes an iterable, but you can instaniate an empty one and update it. \n",
    "word_counts = Counter()\n",
    "\n",
    "# Update it based on a split of each of our documents\n",
    "df['base_tokens'].apply(lambda x: word_counts.update(x))\n",
    "\n",
    "# Print out the 10 most common words\n",
    "word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a fuction which takes a corpus of document and returns and dataframe of word counts for us to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(docs):\n",
    "    '''This function takes a list of tokenized documents as input and returns\n",
    "    a dataframe with \n",
    "    \n",
    "    # Arguments\n",
    "        docs: list, tokenized list of documents\n",
    "        \n",
    "    # Returns\n",
    "        wc: dataframe, \n",
    "    '''\n",
    "    \n",
    "    word_counts = Counter()\n",
    "    appears_in = Counter()\n",
    "\n",
    "    total_docs = len(docs)\n",
    "\n",
    "    for doc in docs:\n",
    "        word_counts.update(doc)\n",
    "        appears_in.update(set(doc))\n",
    "\n",
    "    temp = zip(word_counts.keys(), word_counts.values())\n",
    "\n",
    "    wc = pd.DataFrame(temp, columns = ['word', 'count'])\n",
    "\n",
    "    wc['rank'] = wc['count'].rank(method='first', ascending=False)\n",
    "    total = wc['count'].sum()\n",
    "\n",
    "    wc['pct_total'] = wc['count'].apply(lambda x: x / total)\n",
    "\n",
    "    wc = wc.sort_values(by='rank')\n",
    "    wc['cul_pct_total'] = wc['pct_total'].cumsum()\n",
    "\n",
    "    t2 = zip(appears_in.keys(), appears_in.values())\n",
    "    ac = pd.DataFrame(t2, columns=['word', 'appears_in'])\n",
    "    wc = ac.merge(wc, on='word')\n",
    "\n",
    "    wc['appears_in_pct'] = wc['appears_in'].apply(lambda x: x / total_docs)\n",
    "\n",
    "    return wc.sort_values(by='rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8986, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>appears_in</th>\n",
       "      <th>count</th>\n",
       "      <th>rank</th>\n",
       "      <th>pct_total</th>\n",
       "      <th>cul_pct_total</th>\n",
       "      <th>appears_in_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>the</td>\n",
       "      <td>7809</td>\n",
       "      <td>17723</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.041211</td>\n",
       "      <td>0.041211</td>\n",
       "      <td>0.557985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>and</td>\n",
       "      <td>8543</td>\n",
       "      <td>14005</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.032565</td>\n",
       "      <td>0.073776</td>\n",
       "      <td>0.610432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>it</td>\n",
       "      <td>7490</td>\n",
       "      <td>13113</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.030491</td>\n",
       "      <td>0.104267</td>\n",
       "      <td>0.535191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>7137</td>\n",
       "      <td>12750</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.029647</td>\n",
       "      <td>0.133914</td>\n",
       "      <td>0.509968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>for</td>\n",
       "      <td>7990</td>\n",
       "      <td>12224</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.028424</td>\n",
       "      <td>0.162339</td>\n",
       "      <td>0.570918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  appears_in  count  rank  pct_total  cul_pct_total  appears_in_pct\n",
       "81  the        7809  17723   1.0   0.041211       0.041211        0.557985\n",
       "30  and        8543  14005   2.0   0.032565       0.073776        0.610432\n",
       "14   it        7490  13113   3.0   0.030491       0.104267        0.535191\n",
       "2    to        7137  12750   4.0   0.029647       0.133914        0.509968\n",
       "94  for        7990  12224   5.0   0.028424       0.162339        0.570918"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the Function\n",
    "wc = count(df['base_tokens'])\n",
    "print(wc.shape)\n",
    "wc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cumulative Distribution Plot\n",
    "sns.lineplot(x='rank', y='cul_pct_total', data=wc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6130405666212466"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc[wc['rank'] <= 100]['cul_pct_total'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wc_top20 = wc[wc['rank'] <= 20]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "squarify.plot(sizes=wc_top20['pct_total'], label=wc_top20['word'], alpha=.8 )\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Raw Text with Spacy\n",
    "\n",
    "Spacy's datamodel for documents is unique among NLP libraries. Instead of storing the documents components in various data structures, Spacy indexes components and simply stores the lookup information. \n",
    "\n",
    "This is often why Spacy is considered to be more production grade than library like NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inialize spaCy model and tokenizer\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Friends,', 'Romans,', 'countrymen,', 'lend', 'me', 'your', 'ears;']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out list of tokens\n",
    "sample = \"Friends, Romans, countrymen, lend me your ears;\"\n",
    "[token.text for token in tokenizer(sample)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8343    [Great, case, to, keep, everything, in, its, p...\n",
       "8344    [After, discarding, and, getting, rid, of, bro...\n",
       "8345    [A, few, dollars, more,, but, I, am, boycottin...\n",
       "8346    [My, initial, impression, of, this, was, very,...\n",
       "8347    [Pros:, Standard, Echo., Cons:, Older, generat...\n",
       "Name: spaCy_tokens, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make them tokens using the Tokenizer Pipe\n",
    "tokens = []\n",
    "for doc in tokenizer.pipe(df['reviews.text'], batch_size=500):\n",
    "    doc_tokens = [token.text for token in doc]\n",
    "    tokens.append(doc_tokens)\n",
    "\n",
    "df['spaCy_tokens'] = tokens\n",
    "df['spaCy_tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = count(df['spaCy_tokens'])\n",
    "print(wc.shape)\n",
    "wc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_top20 = wc[wc['rank'] <= 20]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "squarify.plot(sizes=wc_top20['pct_total'], label=wc_top20['word'], alpha=.8 )\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Challenge\n",
    "\n",
    "In the module project, you will apply tokenization to another set of review data and produce visualizations of those tokens. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Stop Words (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Section Agenda\n",
    "- What are they?\n",
    "- How do we get rid of them using Spacy?\n",
    "- Visualization\n",
    "- Libraries of Stop Words\n",
    "- Extending Stop Words\n",
    "- Statistical trimming\n",
    "\n",
    "If the visualizations above, you began to notice a pattern. Most of the words don't really add much to our understanding of product reviews. Words such as \"I\", \"and\", \"of\", etc. have almost no semantic meaning to us. We call these useless words \"stop words,\" because we should 'stop' ourselves from including them in the analysis. \n",
    "\n",
    "Most NLP libraries have built in lists of stop words that common english words: conjunctions, articles, adverbs, pronouns, and common verbs. The best practice, however, is to extend/customize these standard english stopwords for your problem's domain. If I am studying political science, I may want to exclude the word \"politics\" from my analysis; it's so common it does not add to my understanding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along \n",
    "\n",
    "### Default Stop Words\n",
    "Let's take a look at the standard stop words that came with our Spacy model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy's Default Stop Words\n",
    "nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "\n",
    "# Return lower case tokens and ignore stop words/punctuation\n",
    "for doc in tokenizer.pipe(df['reviews.text'], batch_size=500):\n",
    "    \n",
    "    doc_tokens = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if (token.is_stop == False) & (token.is_punct == False):\n",
    "            doc_tokens.append(token.text.lower())\n",
    "\n",
    "    tokens.append(doc_tokens)\n",
    "\n",
    "df['spaCy_tokens_v2'] = tokens\n",
    "df['spaCy_tokens_v2'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = count(df['spaCy_tokens_v2'])\n",
    "print(wc.shape)\n",
    "wc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_top20 = wc[wc['rank'] <= 20]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "squarify.plot(sizes=wc_top20['pct_total'], label=wc_top20['word'], alpha=.8 )\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extending Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(nlp.Defaults.stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = nlp.Defaults.stop_words.union(['batteries','I', 'amazon', 'i', 'Amazon', 'it', \"it's\", 'it.', 'the', 'this'])\n",
    "STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for doc in tokenizer.pipe(df['reviews.text'], batch_size=500):\n",
    "    \n",
    "    doc_tokens = []\n",
    "    for token in doc: \n",
    "        if token.text.lower() not in STOP_WORDS:\n",
    "            doc_tokens.append(token.text.lower())\n",
    "   \n",
    "    tokens.append(doc_tokens)\n",
    "    \n",
    "df['spaCy_tokens_v3'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = count(df['spaCy_tokens_v3'])\n",
    "print(wc.shape)\n",
    "wc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make this comparison more interesting, let's compare: All Amazon Reviews, Fire HD 8 only, and Kindle only\n",
    "df['FireHD_8'] = df['name'].str.contains('fire hd 8', case=False)\n",
    "df['Kindle'] = df['name'].str.contains('kindle', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Function for all reviews, Fire HD 8 only, and Kindle only\n",
    "wc = count(df['spaCy_tokens_v3'])\n",
    "wc_fire_hd_8 = count(df[df['FireHD_8'] == 1]['spaCy_tokens_v3'])\n",
    "wc_kindle = count(df[df['Kindle'] == 1]['spaCy_tokens_v3'])\n",
    "print(wc.shape, wc_fire_hd_8.shape, wc_kindle.shape)\n",
    "\n",
    "# Get top 20 word occurences for each set of data\n",
    "wc_top20 = wc[wc['rank'] <= 20]\n",
    "wc_fire_top20 = wc_fire_hd_8[wc_fire_hd_8['rank'] <= 20]\n",
    "wc_kindle_top20 = wc_kindle[wc_kindle['rank'] <= 20]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "axes[0].set_title('All Amazon Reviews')\n",
    "squarify.plot(sizes=wc_top20['pct_total'], label=wc_top20['word'], alpha=.8, ax=axes[0])\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].set_title('Fire HD 8 Tablet')\n",
    "squarify.plot(sizes=wc_fire_top20['pct_total'], label=wc_fire_top20['word'], alpha=.8, ax=axes[1])\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].set_title('Kindle')\n",
    "squarify.plot(sizes=wc_kindle_top20['pct_total'], label=wc_kindle_top20['word'], alpha=.8, ax=axes[2])\n",
    "axes[2].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews.rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Trimming\n",
    "\n",
    "So far, we have talked about stop word in relation to either broad english words or domain specific stop words. Another common approach to stop word removal is via statistical trimming. The basic idea: preserve the words that give the most about of variation in your data. \n",
    "\n",
    "Do you remember this graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='rank', y='cul_pct_total', data=wc);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph tells us that only a *handful* of words represented 80% of words in the overall corpus. We can interpret this in two ways: \n",
    "1. The words that appear most frequently may not provide any insight into the mean on the documents since they are so prevalent. \n",
    "2. Words that appear infrequency (at the end of the graph) also probably do not add much value, because the are mentioned so rarely. \n",
    "\n",
    "Let's take a look at the words at the bottom and the top and make a decision for ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc['appears_in_pct'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of appears in documents\n",
    "sns.distplot(wc['appears_in_pct']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree-Map w/ Words that appear in a least 0.1% of documents. \n",
    "wc = wc[wc['appears_in_pct'] >= 0.001]\n",
    "sns.distplot(wc['appears_in_pct']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "In the module project, you will apply stop word removal to a new corpus. You will focus on applying dictionary based stop word removal, but as a stretch goal, you should consider applying statistical stopword trimming. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Stemming & Lemmatization (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Overview\n",
    "\n",
    "You can see from our example above there is still some normalization to do to get a clean analysis. You notice that there many words (*i.e.* 'batteries', 'battery') which share the same root word. We can use either the process of stemming or lemmatization to trim our words down to the 'root' word. \n",
    "\n",
    "__Section Agenda__:\n",
    "\n",
    "- Which is which\n",
    "- why use one v. other\n",
    "- show side by side visualizations \n",
    "- how to do it in spacy & nltk\n",
    "- introduce PoS in here as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Stemming\n",
    "\n",
    "> *a process for removing the commoner morphological and inflexional endings from words in English. Its main use is as part of a term normalisation process that is usually done when setting up Information Retrieval systems.* - [Martin Porter](https://tartarus.org/martin/PorterStemmer/)\n",
    "\n",
    "Some examples include:\n",
    "- 'ing'\n",
    "- 'ed'\n",
    "- 's'\n",
    "\n",
    "These rules are by no means comprehensive, but they are somewhere to start. Most stemming is done by well documented algorithms such as Porter, Snowball, and Dawson. Porter and its newer version Snowball are the most popular stemming algorithms today. For more information on various stemming algorithms check out [*\"A Comparative Study of Stemming Algorithms\"*](https://pdfs.semanticscholar.org/1c0c/0fa35d4ff8a2f925eb955e48d655494bd167.pdf) \n",
    "\n",
    "\n",
    "Spacy does not do stemming out of the box, but instead uses a different technique called *lemmatization* which we will discuss in the next section. Let's turn to an antique python package `nltk` for stemming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "words = [\"python\", \"pythoner\", \"pythoning\", \"pythoned\", \"pythonly\"]\n",
    "for word in words:\n",
    "    print(ps.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Minute Challenge\n",
    "\n",
    "Apply the Porter stemming algorithm to the tokens in the `df` dataframe. Visualize the results in the tree graph we have been using for this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leverage tqdm for progress_apply\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put in a new column `stems`\n",
    "df['stems'] = df.tokens.progress_apply(lambda x: [ps.stem(word) for word in x])\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = count(df['stems'])\n",
    "print(wc.shape)\n",
    "wc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_top20 = wc[wc['rank'] <= 20]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "squarify.plot(sizes=wc_top20['pct_total'], label=wc_top20['word'], alpha=.8 )\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Lemmatization\n",
    "\n",
    "You notice immediately that results are kinda funky - words just oddly chopped off. The Porter algorithm did exactly what it knows to do: chop off endings. Stemming works well in applications where humans don't have to worry about reading the results. Search engines and more broadly information retrieval algorithms use stemming. Why? Because it's fast. \n",
    "\n",
    "Lemmatization on the other hand is more methodical. The goal is to transform a word into its base form called a lemma. Plural nouns with funky spellings get transformed to singular tense. Verbs are all transformed to the transitive. Nice tidy data for a visualization. :) However, this tidy data can come at computational cost. Spacy does a pretty freaking good job of it though. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"This is the start of our NLP adventures. We started here with Spacy. We are starting here with NLP.\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(sent)\n",
    "\n",
    "# Lemma Attributes\n",
    "for token in doc:\n",
    "    print(token.text, \"  \", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap it all in a function\n",
    "def get_lemmas(text):\n",
    "\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    lemmas = []\n",
    "    for token in doc: \n",
    "        if ((token.is_stop == False) and (token.is_punct == False)) and (token.pos_ != 'PRON'):\n",
    "            lemmas.append(token.lemma_)\n",
    "    \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmas'] = df['reviews.text'].progress_apply(get_lemmas)\n",
    "df['lemmas'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = count(df['lemmas'])\n",
    "print(wc.shape)\n",
    "wc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_top20 = wc[wc['rank'] <= 20]\n",
    "\n",
    "squarify.plot(sizes=wc_top20['pct_total'], label=wc_top20['word'], alpha=.8 )\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You should know how to apply lemmatization with Spacy to a corpus of text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Material (if time permits)\n",
    "\n",
    "Go to terminal:\n",
    "- conda activate U4-S1-NLP\n",
    "- conda install -c conda-forge textblob\n",
    "\n",
    "Good reference article: https://planspace.org/20150607-textblob_sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(30,1)})\n",
    "\n",
    "def visualise_sentiments(data):\n",
    "    sns.heatmap(pd.DataFrame(data).set_index(\"Sentence\").T,center=0, annot=True, cmap = \"PiYG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Sentiment analysis (or opinion mining) attempts to determine if a text is objective or subjective, positive or negative.\n",
    "# The sentiment analysis lexicon bundled in Pattern focuses on adjectives.\n",
    "# It contains adjectives that occur frequently in customer reviews, hand-tagged with values for polarity and subjectivity.\n",
    "\n",
    "# Calculate sentiment\n",
    "TextBlob(\"Textblob makes it simple and easy to calculate sentiment\").sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = df['reviews.text'].iloc[0]\n",
    "print(sentence)\n",
    "TextBlob(sentence).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_sentiments({\n",
    "      \"Sentence\":[\"SENTENCE\"] + sentence.split(),\n",
    "      \"Sentiment\":[TextBlob(sentence).polarity] + [TextBlob(word).polarity for word in sentence.split()],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spelling correction\n",
    "TextBlob(\"Textblob also makes it simple and esy to corectt speling\").correct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scattertext Kindle vs. FireHD Comparison\n",
    "\n",
    "Go to terminal: \n",
    "\n",
    "- pip install scattertext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy and add column with product tags\n",
    "subset_df = df.copy()\n",
    "subset_df.loc[subset_df['name'].str.contains('kindle', case=False), 'product'] = 'Kindle'\n",
    "subset_df.loc[subset_df['name'].str.contains('fire hd 8', case=False), 'product'] = 'Fire HD 8'\n",
    "\n",
    "# Drop Review that aren't Kindle/Fire HD 8\n",
    "subset_df.dropna(subset=['product'], inplace=True)\n",
    "\n",
    "# Confirm shape and distribution of reviews\n",
    "print(subset_df.shape)\n",
    "subset_df['product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scattertext as st\n",
    "\n",
    "corpus = st.CorpusFromPandas(subset_df, \n",
    "                             category_col='product', \n",
    "                             text_col='reviews.text',\n",
    "                             nlp=nlp).build()\n",
    "\n",
    "html = st.produce_scattertext_explorer(\n",
    "    corpus,\n",
    "    category='Kindle',\n",
    "    category_name='Kindle',\n",
    "    not_category_name='Fire HD 8',\n",
    "    width_in_pixels=1000,\n",
    "    metadata=subset_df['reviews.rating'])\n",
    "open('./kindle_vs_firehd8.html', 'w').write(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "In this module project, you've seen us apply Natural Language Processing techniques (tokenization, stopword removal, and lemmatization) to a corpus of Amazon text reviews. We analyzed those reviews using these techniques and discovered that Amazon customers are generally satisfied with the battery life of Amazon products and generally appear satisfied. \n",
    "\n",
    "You will apply similar techniques to today's [module project assignment](LS_DS_411_Text_Data_Assignment.ipynb) to analyze coffee shop reviews from yelp. Remember that the techniques of processing the text are just the beginning. There are many ways to slice and dice the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "* Spacy 101 - https://course.spacy.io\n",
    "* NLTK Book - https://www.nltk.org/book/\n",
    "* An Introduction to Information Retrieval - https://nlp.stanford.edu/IR-book/pdf/irbookonlinereading.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Advanced Resources & Techniques\n",
    "- Named Entity Recognition (NER)\n",
    "- Dependcy Trees \n",
    "- Generators\n",
    "- the major libraries (NLTK, Spacy, Gensim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
